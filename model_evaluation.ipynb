{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK: 02\n",
    "# Object Detection System using Ultralytics\n",
    "## Models Evaluation\n",
    "We will visualize and evaluate the models on the validation dataset and show various metrics for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will use the FER2013 Dataset which contains __10__ classes, as listed below:\n",
    "1. Hardhat\n",
    "2. Mask\n",
    "3. NO-Hardhat\n",
    "4. NO-Mask\n",
    "5. NO-Safety Vest\n",
    "6. Person\n",
    "7. Safety Cone\n",
    "8. Safety Vest\n",
    "9. machinery\n",
    "10. vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# let's load our models for evaluation\n",
    "yolo_mobilenet = YOLO('YOLOv8_MobileNet/weights/best.pt')\n",
    "yolo_resnet50 = YOLO('YOLOv8_ResNet50/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.51  Python-3.12.4 torch-2.3.1+cpu CPU (12th Gen Intel Core(TM) i5-1235U)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\wajah\\Desktop\\PPE_Detection\\css-data\\valid\\labels... 114 images, 10 backgrounds, 0 corrupt: 100%|██████████| 114/114 [00:00<00:00, 1297.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\wajah\\Desktop\\PPE_Detection\\css-data\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [01:22<00:00, 10.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114        697      0.796      0.578      0.641      0.331\n",
      "               Hardhat         42         79      0.884      0.677      0.735      0.443\n",
      "                  Mask         19         21      0.918       0.81      0.824      0.516\n",
      "            NO-Hardhat         37         69       0.82      0.507      0.586      0.263\n",
      "               NO-Mask         44         74      0.873      0.432      0.558      0.218\n",
      "        NO-Safety Vest         56        106      0.766      0.472      0.569      0.258\n",
      "                Person         84        166      0.694      0.589      0.598      0.276\n",
      "           Safety Cone         13         44      0.864      0.818       0.86       0.45\n",
      "           Safety Vest         28         41      0.889      0.586      0.724      0.415\n",
      "             machinery         26         55      0.631        0.6      0.622      0.293\n",
      "               vehicle         16         42      0.617      0.286      0.338      0.176\n",
      "Speed: 3.0ms preprocess, 707.8ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n",
      "Ultralytics YOLOv8.2.51  Python-3.12.4 torch-2.3.1+cpu CPU (12th Gen Intel Core(TM) i5-1235U)\n",
      "YOLOv8-resnet50 summary (fused): 273 layers, 25503822 parameters, 0 gradients, 72.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\wajah\\Desktop\\PPE_Detection\\css-data\\valid\\labels.cache... 114 images, 10 backgrounds, 0 corrupt: 100%|██████████| 114/114 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [02:43<00:00, 20.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114        697      0.854      0.613      0.681      0.366\n",
      "               Hardhat         42         79      0.983      0.719      0.813      0.479\n",
      "                  Mask         19         21       0.95       0.81      0.847      0.507\n",
      "            NO-Hardhat         37         69      0.903      0.522      0.581      0.273\n",
      "               NO-Mask         44         74      0.926      0.504      0.614      0.286\n",
      "        NO-Safety Vest         56        106      0.757      0.491      0.559      0.276\n",
      "                Person         84        166      0.742      0.639      0.689       0.32\n",
      "           Safety Cone         13         44        0.9      0.773      0.818      0.417\n",
      "           Safety Vest         28         41      0.946      0.659      0.747      0.453\n",
      "             machinery         26         55      0.784      0.726      0.763      0.437\n",
      "               vehicle         16         42      0.651      0.286      0.381      0.213\n",
      "Speed: 3.9ms preprocess, 1421.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test subset\n",
    "test_data = 'data.yaml'\n",
    "results_mobilenet = yolo_mobilenet.val(data=test_data)\n",
    "results_resnet50 = yolo_resnet50.val(data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model with ResNet50 backbone performs better overall with mAP@0.5 = 0.68, over all classes.\n"
     ]
    }
   ],
   "source": [
    "# Compare mAP@50%\n",
    "if results_mobilenet.box.map50 > results_resnet50.box.map50:\n",
    "    print(f\"\\nModel with MobileNet backbone performs better with mAP@0.5 = {results_mobilenet.box.map50:.2f}, over all classes.\")\n",
    "elif results_mobilenet.box.map50 < results_resnet50.box.map50:\n",
    "    print(f\"\\nModel with ResNet50 backbone performs better overall with mAP@0.5 = {results_resnet50.box.map50:.2f}, over all classes.\")\n",
    "else:\n",
    "    print(\"\\nBoth models perform similarly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv8 MobileNet Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 Hardhats, 1 NO-Safety Vest, 4 Persons, 2 Safety Vests, 508.0ms\n",
      "1: 640x640 2 Hardhats, 1 Mask, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 2 Safety Vests, 508.0ms\n",
      "2: 640x640 6 Hardhats, 8 NO-Masks, 1 NO-Safety Vest, 8 Persons, 5 Safety Vests, 508.0ms\n",
      "3: 640x640 2 Hardhats, 1 NO-Hardhat, 3 NO-Masks, 2 Persons, 1 Safety Vest, 508.0ms\n",
      "Speed: 5.9ms preprocess, 508.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "test_images = ['source_files\\\\' + image for image in os.listdir(\n",
    "    'source_files') if image.endswith('.jpg')]\n",
    "results = yolo_mobilenet(test_images)  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save('results/' + result.path.split('\\\\')[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ul-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
